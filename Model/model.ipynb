{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from math import inf\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Image.open(\"train/cat.0.jpg\")\n",
    "# cats: 0 -> 12499; dogs: 0 -> 12499\n",
    "\n",
    "# resize to 128 x 128\n",
    "\n",
    "\"\"\"\n",
    "0 = Cat\n",
    "1 = Dog\n",
    "\"\"\"\n",
    "\n",
    "X = np.zeros((25000, 128, 128, 3), dtype = np.float32)\n",
    "labels = np.zeros(25000, dtype=np.float32)\n",
    "k = 0\n",
    "for i in range(12500):\n",
    "    im = Image.open(f\"train/cat.{i}.jpg\")\n",
    "    im = im.resize((128,128))\n",
    "    im = np.array(np.array(im))\n",
    "    labels[k] = 0\n",
    "    X[k] = im\n",
    "    k += 1\n",
    "    im = Image.open(f\"train/dog.{i}.jpg\")\n",
    "    im = im.resize((128,128))\n",
    "    im = np.array(np.array(im))\n",
    "    labels[k] = 1\n",
    "    X[k] = im\n",
    "    k += 1\n",
    "\n",
    "X = torch.from_numpy(X).permute(dims=(0,3,1,2))\n",
    "labels = torch.from_numpy(labels)\n",
    "\n",
    "## need to fix the shuffle thing. corresponding labels should also shuffle along with X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(255.)\n",
      "(0.4883098900318146, 0.45507100224494934, 0.41694772243499756) (0.25926217436790466, 0.25269168615341187, 0.25525805354118347)\n"
     ]
    }
   ],
   "source": [
    "print(X.max())\n",
    "X = X/X.max()\n",
    "mean =  (X[:,0].mean().item(), X[:, 1].mean().item(), X[:,2].mean().item())\n",
    "std = (X[:,0].std().item(), X[:, 1].std().item(), X[:,2].std().item())\n",
    "normalize = Normalize(mean, std)\n",
    "X = normalize(X)\n",
    "size = 20000\n",
    "train_X = X[:size]; train_Y = labels[:size]\n",
    "validation_X = X[size:]; validation_Y = labels[size:]\n",
    "X = None; labels = None\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    def __init__(self, X, labels):\n",
    "        self.data = X\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        arr = torch.zeros(2)\n",
    "        arr[int(self.labels[indx].item())] = 1\n",
    "        return (self.data[indx], arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(X = train_X, labels = train_Y)\n",
    "valset = CustomDataset(X = validation_X, labels = validation_Y)\n",
    "\n",
    "TrainLoader = DataLoader(dataset=trainset, batch_size=20, shuffle=True, num_workers=2)\n",
    "ValidationLoader = DataLoader(dataset=valset, batch_size=20, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Data: 9958/20000  49.79%\n",
      "Testing Data: 2492/5000  49.84%\n",
      "===============================================================\n",
      "Epoch: 1\n",
      "Training Data: 15143/20000  75.715%\n",
      "Testing Data: 3764/5000  75.28%\n",
      "===============================================================\n",
      "Epoch: 2\n",
      "Training Data: 16117/20000  80.585%\n",
      "Testing Data: 4020/5000  80.4%\n",
      "===============================================================\n",
      "Epoch: 3\n",
      "Training Data: 16629/20000  83.145%\n",
      "Testing Data: 4097/5000  81.94%\n",
      "===============================================================\n",
      "Epoch: 4\n",
      "Training Data: 17166/20000  85.83%\n",
      "Testing Data: 4227/5000  84.54%\n",
      "===============================================================\n",
      "Epoch: 5\n",
      "Training Data: 17313/20000  86.565%\n",
      "Testing Data: 4240/5000  84.8%\n",
      "===============================================================\n",
      "Epoch: 6\n",
      "Training Data: 17478/20000  87.39%\n",
      "Testing Data: 4313/5000  86.26%\n",
      "===============================================================\n",
      "Epoch: 7\n",
      "Training Data: 17729/20000  88.645%\n",
      "Testing Data: 4330/5000  86.6%\n",
      "===============================================================\n",
      "Epoch: 8\n",
      "Training Data: 17947/20000  89.735%\n",
      "Testing Data: 4350/5000  87.0%\n",
      "===============================================================\n",
      "Epoch: 9\n",
      "Training Data: 17783/20000  88.915%\n",
      "Testing Data: 4306/5000  86.12%\n",
      "===============================================================\n",
      "Epoch: 10\n",
      "Training Data: 18067/20000  90.335%\n",
      "Testing Data: 4402/5000  88.04%\n",
      "===============================================================\n",
      "Epoch: 11\n",
      "Training Data: 18014/20000  90.07%\n",
      "Testing Data: 4360/5000  87.2%\n",
      "===============================================================\n",
      "Epoch: 12\n",
      "Training Data: 18255/20000  91.275%\n",
      "Testing Data: 4440/5000  88.8%\n",
      "===============================================================\n",
      "Epoch: 13\n",
      "Training Data: 18217/20000  91.085%\n",
      "Testing Data: 4396/5000  87.92%\n",
      "===============================================================\n",
      "Epoch: 14\n",
      "Training Data: 18271/20000  91.355%\n",
      "Testing Data: 4422/5000  88.44%\n",
      "===============================================================\n",
      "Epoch: 15\n",
      "Training Data: 18315/20000  91.575%\n",
      "Testing Data: 4401/5000  88.02%\n",
      "===============================================================\n",
      "Epoch: 16\n",
      "Training Data: 18482/20000  92.41%\n",
      "Testing Data: 4451/5000  89.02%\n",
      "===============================================================\n",
      "Epoch: 17\n",
      "Training Data: 18568/20000  92.84%\n",
      "Testing Data: 4431/5000  88.62%\n",
      "===============================================================\n",
      "Epoch: 18\n",
      "Training Data: 18671/20000  93.355%\n",
      "Testing Data: 4452/5000  89.04%\n",
      "===============================================================\n",
      "Epoch: 19\n",
      "Training Data: 18458/20000  92.29%\n",
      "Testing Data: 4389/5000  87.78%\n",
      "===============================================================\n",
      "Epoch: 20\n",
      "Training Data: 18631/20000  93.155%\n",
      "Testing Data: 4432/5000  88.64%\n",
      "===============================================================\n",
      "Epoch: 21\n",
      "Training Data: 18613/20000  93.065%\n",
      "Testing Data: 4382/5000  87.64%\n",
      "===============================================================\n",
      "Epoch: 22\n",
      "Training Data: 18678/20000  93.39%\n",
      "Testing Data: 4441/5000  88.82%\n",
      "===============================================================\n",
      "Epoch: 23\n",
      "Training Data: 18650/20000  93.25%\n",
      "Testing Data: 4420/5000  88.4%\n",
      "===============================================================\n",
      "Epoch: 24\n",
      "Training Data: 18730/20000  93.65%\n",
      "Testing Data: 4432/5000  88.64%\n",
      "===============================================================\n",
      "Epoch: 25\n",
      "Training Data: 18932/20000  94.66%\n",
      "Testing Data: 4475/5000  89.5%\n",
      "===============================================================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, lr):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, padding=1) # 6 x 128 x 128\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=6)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=4) # 6 x 32 x 32\n",
    "\n",
    "        class Block(nn.Module):\n",
    "            def __init__(this, features):\n",
    "                super().__init__()\n",
    "                this.num_featues = features\n",
    "                this.conv1 = nn.Conv2d(in_channels=this.num_featues, out_channels=this.num_featues, kernel_size=3, padding=1)\n",
    "                this.conv2 = nn.Conv2d(in_channels=this.num_featues, out_channels=this.num_featues, kernel_size=3, padding=1)\n",
    "                this.bn = nn.BatchNorm2d(num_features=this.num_featues)\n",
    "            def forward(this, x):\n",
    "                y = torch.relu(this.bn(this.conv1(x)))\n",
    "                y = this.bn(this.conv2(y))\n",
    "                return torch.relu(this.bn(x + y))\n",
    "            \n",
    "            __call__ = forward\n",
    "\n",
    "        self.blocks1 = nn.ModuleList([Block(6) for i in range(3)]) # bn1 works\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=24, kernel_size=3, padding=1) # 24 x 32 x 32\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=24)\n",
    "        # use self.maxpool again -----------------> # 24 x 8 x 8\n",
    "\n",
    "        self.blocks2 = nn.ModuleList([Block(24) for i in range(3)])\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2) # 24 x 4 x 4\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=32)\n",
    "        self.l1 = nn.Linear(in_features=24*4*4, out_features=32)\n",
    "        self.l2 = nn.Linear(in_features=32, out_features=2)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(params=self.parameters(), lr=lr, weight_decay=0.00001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        for block in self.blocks1:\n",
    "            x = block(x)\n",
    "        x = self.maxpool(self.dropout(torch.relu(self.bn2(self.conv2(x)))))\n",
    "        for block in self.blocks2:\n",
    "            x = block(x)\n",
    "        x = self.avg_pool(self.dropout(x))\n",
    "        x = torch.relu(self.l1(x.view(-1, 24*4*4)))\n",
    "        x = torch.sigmoid(self.l2(x))\n",
    "        # x = torch.softmax(self.l2(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def train(self, train_loader: DataLoader, validation_loader: DataLoader|None, epochs = 20):\n",
    "        epochs += 1\n",
    "        for epoch in range(epochs):\n",
    "            for idx, (data, label) in enumerate(train_loader):\n",
    "                if epoch == 0:\n",
    "                    continue\n",
    "                data, label = data.to(device), label.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                y_pred = self.forward(data)\n",
    "                if y_pred.isnan().any():\n",
    "                    print(0)\n",
    "                    raise Exception(\"NaN\")\n",
    "                loss = self.loss(label, y_pred)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print(\"Epoch:\", epoch)\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = len(train_loader)*train_loader.batch_size\n",
    "                for idx, (data, label) in enumerate(train_loader):\n",
    "                    data, label = data.to(device), label.to(device)\n",
    "                    y_pred = self.forward(data)\n",
    "                    correct += (y_pred.argmax(dim=1) == label.argmax(dim=1)).sum().item()\n",
    "\n",
    "                print(f\"Training Data: {correct}/{total}  {correct*100/total}%\")\n",
    "                if validation_loader == None:\n",
    "                    continue\n",
    "                correct = 0\n",
    "                total = len(validation_loader)*validation_loader.batch_size\n",
    "                for idx, (data, label) in enumerate(validation_loader):\n",
    "                    data, label = data.to(device), label.to(device)\n",
    "                    y_pred = self.forward(data)\n",
    "                    correct += (y_pred.argmax(dim=1) == label.argmax(dim=1)).sum().item()\n",
    "\n",
    "                print(f\"Testing Data: {correct}/{total}  {correct*100/total}%\")\n",
    "            print(\"===============================================================\")\n",
    "\n",
    "\n",
    "model = Model(lr=0.001)\n",
    "model.to(device)\n",
    "\n",
    "model.train(train_loader=TrainLoader, validation_loader=ValidationLoader, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLoader = None\n",
    "ValidationLoader = None\n",
    "trainset = None\n",
    "valset = None\n",
    "\n",
    "X = torch.concat([train_X, validation_X])\n",
    "Y = torch.concat([train_Y, validation_Y])\n",
    "\n",
    "train_X = None; validation_X = None; train_Y = None; validation_Y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(X = X, labels = Y)\n",
    "TrainLoader = DataLoader(dataset=trainset, batch_size=20, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Data: 12365/25000  49.46%\n",
      "Epoch: 1\n",
      "Training Data: 19161/25000  76.644%\n",
      "Epoch: 2\n",
      "Training Data: 20152/25000  80.608%\n",
      "Epoch: 3\n",
      "Training Data: 20785/25000  83.14%\n",
      "Epoch: 4\n",
      "Training Data: 21169/25000  84.676%\n",
      "Epoch: 5\n",
      "Training Data: 21414/25000  85.656%\n",
      "Epoch: 6\n",
      "Training Data: 21705/25000  86.82%\n",
      "Epoch: 7\n",
      "Training Data: 21784/25000  87.136%\n",
      "Epoch: 8\n",
      "Training Data: 21974/25000  87.896%\n",
      "Epoch: 9\n",
      "Training Data: 21957/25000  87.828%\n",
      "Epoch: 10\n",
      "Training Data: 22216/25000  88.864%\n",
      "Epoch: 11\n",
      "Training Data: 22376/25000  89.504%\n",
      "Epoch: 12\n",
      "Training Data: 22539/25000  90.156%\n",
      "Epoch: 13\n",
      "Training Data: 22393/25000  89.572%\n",
      "Epoch: 14\n",
      "Training Data: 22622/25000  90.488%\n",
      "Epoch: 15\n",
      "Training Data: 22698/25000  90.792%\n",
      "Epoch: 16\n",
      "Training Data: 22744/25000  90.976%\n",
      "Epoch: 17\n",
      "Training Data: 22913/25000  91.652%\n",
      "Epoch: 18\n",
      "Training Data: 22904/25000  91.616%\n",
      "Epoch: 19\n",
      "Training Data: 22939/25000  91.756%\n",
      "Epoch: 20\n",
      "Training Data: 22949/25000  91.796%\n",
      "Epoch: 21\n",
      "Training Data: 23245/25000  92.98%\n",
      "Epoch: 22\n",
      "Training Data: 23183/25000  92.732%\n",
      "Epoch: 23\n",
      "Training Data: 23384/25000  93.536%\n",
      "Epoch: 24\n",
      "Training Data: 23347/25000  93.388%\n",
      "Epoch: 25\n",
      "Training Data: 23296/25000  93.184%\n"
     ]
    }
   ],
   "source": [
    "model = Model(lr=0.001)\n",
    "model.to(device)\n",
    "\n",
    "model.train(train_loader=TrainLoader, validation_loader=None, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
